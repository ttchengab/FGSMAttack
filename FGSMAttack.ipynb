{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install the dependencies\n",
    "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
    "!pip install advertorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from cleverhans.compat import flags\n",
    "from cleverhans.train import train\n",
    "from cleverhans.dataset import MNIST\n",
    "from cleverhans.utils import AccuracyReport\n",
    "from cleverhans.utils_tf import model_eval\n",
    "\n",
    "#Attack on PyTorch\n",
    "from cleverhans.future.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "\n",
    "#advertorch attacks\n",
    "from advertorch.attacks import CarliniWagnerL2Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple network\n",
    "class LeNet5(torch.nn.Module):          \n",
    "     \n",
    "    def __init__(self):     \n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)   \n",
    "        self.fc2 = nn.Linear(120, 84)       \n",
    "        self.fc3 = nn.Linear(84, 10)    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  \n",
    "        x = F.max_pool2d(x, 2) \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x,dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "NB_EPOCHS = 2\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = .001\n",
    "\n",
    "#Training the Network\n",
    "def trainTorch(torch_model, train_loader, test_loader,\n",
    "        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE, train_end=-1, test_end=-1, learning_rate=LEARNING_RATE, optimizer=None):\n",
    "\n",
    "    train_loss = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    step = 0\n",
    "    for _epoch in range(nb_epochs):\n",
    "      for xs, ys in train_loader:\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "          xs, ys = xs.cuda(), ys.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        preds = torch_model(xs)\n",
    "        # print(\"HI\")\n",
    "        loss = F.nll_loss(preds, ys)\n",
    "        # print(\"HADSFSDF\")\n",
    "        loss.backward()  # calc gradients\n",
    "        train_loss.append(loss.data.item())\n",
    "        optimizer.step()  # update gradients\n",
    "\n",
    "        preds_np = preds.cpu().detach().numpy()\n",
    "        correct += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
    "        total += train_loader.batch_size\n",
    "        step += 1\n",
    "        if total % 1000 == 0:\n",
    "          acc = float(correct) / total\n",
    "          print('[%s] Training accuracy: %.2f%%' % (step, acc * 100))\n",
    "          total = 0\n",
    "          correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate results on clean data\n",
    "def evalClean(model1=None, test_loader=None):\n",
    "    print(\"Evaluating single model results on clean data\")\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "      model1.eval()\n",
    "      for xs, ys in test_loader:\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "          xs, ys = xs.cuda(), ys.cuda()\n",
    "        preds1 = model1(xs)\n",
    "        preds_np1 = preds1.cpu().detach().numpy()\n",
    "        finalPred = np.argmax(preds_np1, axis=1)\n",
    "        correct += (finalPred == ys.cpu().detach().numpy()).sum()\n",
    "        total += len(xs)\n",
    "    acc = float(correct) / total\n",
    "    print('Clean accuracy: %.2f%%' % (acc * 100))\n",
    "\n",
    "#Evaluate results on adversarially perturbed \n",
    "def evalAdvAttack(fgsm_model=None, test_loader=None):\n",
    "    print(\"Evaluating single model results on adv data\")\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    fgsm_model.eval()\n",
    "    for xs, ys in test_loader:\n",
    "      if torch.cuda.is_available():\n",
    "        xs, ys = xs.cuda(), ys.cuda()\n",
    "      #pytorch fast gradient method\n",
    "      xs = fast_gradient_method(fgsm_model, xs, eps=0.1, norm=np.inf, clip_min=0., clip_max=1.)\n",
    "      # xs = fast_gradient_method(fgsm_model, xs, eps=0.1, norm=np.inf)\n",
    "      xs, ys = Variable(xs), Variable(ys)\n",
    "      preds1 = fgsm_model(xs)\n",
    "      preds_np1 = preds1.cpu().detach().numpy()\n",
    "      finalPred = np.argmax(preds_np1, axis=1)\n",
    "      correct += (finalPred == ys.cpu().detach().numpy()).sum()\n",
    "      total += test_loader.batch_size\n",
    "    acc = float(correct) / total\n",
    "    print('Adv accuracy: {:.3f}ï¼…'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adversarial Training\n",
    "def advTrain(torch_model, train_loader, test_loader,\n",
    "        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE, train_end=-1, test_end=-1, learning_rate=LEARNING_RATE):\n",
    "    optimizer = optim.Adam(torch_model.parameters(), lr=learning_rate)\n",
    "    train_loss = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    totalAdv = 0\n",
    "    correctAdv = 0\n",
    "    step = 0\n",
    "    # breakstep = 0\n",
    "    for _epoch in range(nb_epochs):\n",
    "      for xs, ys in train_loader:\n",
    "        #Normal Training\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "          xs, ys = xs.cuda(), ys.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        preds = torch_model(xs)\n",
    "        loss = F.nll_loss(preds, ys)\n",
    "        loss.backward()  # calc gradients\n",
    "        train_loss.append(loss.data.item())\n",
    "        optimizer.step()  # update gradients\n",
    "        preds_np = preds.cpu().detach().numpy()\n",
    "        correct += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
    "        total += train_loader.batch_size\n",
    "\n",
    "        #Adversarial Training\n",
    "        xs = fast_gradient_method(torch_model, xs, eps=0.3, norm=np.inf, clip_min=0., clip_max=1.)\n",
    "        xs, ys = Variable(xs), Variable(ys)\n",
    "        if torch.cuda.is_available():\n",
    "            xs, ys = xs.cuda(), ys.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        preds = torch_model(xs)\n",
    "        loss = F.nll_loss(preds, ys)\n",
    "        loss.backward()  # calc gradients\n",
    "        train_loss.append(loss.data.item())\n",
    "        optimizer.step()  # update gradients\n",
    "        preds_np = preds.cpu().detach().numpy()\n",
    "        correctAdv += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
    "        totalAdv += train_loader.batch_size\n",
    "        \n",
    "        step += 1\n",
    "        if total % 1000 == 0:\n",
    "          acc = float(correct) / total\n",
    "          print('[%s] Clean Training accuracy: %.2f%%' % (step, acc * 100))\n",
    "          total = 0\n",
    "          correct = 0\n",
    "          accAdv = float(correctAdv) / totalAdv\n",
    "          print('[%s] Adv Training accuracy: %.2f%%' % (step, accAdv * 100))\n",
    "          totalAdv = 0\n",
    "          correctAdv = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model and data loader\n",
    "model1 = LeNet5()\n",
    "if torch.cuda.is_available():\n",
    "  model1 = model1.cuda()\n",
    "nb_epochs = 4\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "train_end = -1\n",
    "test_end = -1\n",
    "report = AccuracyReport()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                    transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "print(\"Training Model\")\n",
    "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)\n",
    "trainTorch(model1, train_loader, test_loader, nb_epochs, batch_size, train_end, test_end, learning_rate, optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "evalClean(model1, test_loader)\n",
    "evalAdvAttack(model1, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training on Adversarial Samples\")\n",
    "advTrain(model1, train_loader, test_loader, nb_epochs, batch_size, train_end, test_end, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Again\n",
    "evalClean(model1, test_loader)\n",
    "evalAdvAttack(model1, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
